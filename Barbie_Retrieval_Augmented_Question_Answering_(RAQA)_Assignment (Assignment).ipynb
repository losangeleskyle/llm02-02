{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI-Maker-Space/LLM-Ops-Vault/blob/main/Week%201/First%20Session/Barbie_Retrieval_Augmented_Question_Answering_(RAQA)_Assignment%20(Completed).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLi09z_3qW8O"
      },
      "source": [
        "# Questioning Barbie Reviews with RAQA (Retrieval Augmented Question Answering)\n",
        "\n",
        "In the following notebook, you are tasked with creating a system that answers questions based on information found in reviews of the 2023 Barbie movie.\n",
        "\n",
        "## Build ðŸ—ï¸\n",
        "\n",
        "There are 3 main tasks in this notebook:\n",
        "\n",
        "1. Obtain and parse reviews from a review website\n",
        "2. Create a Vectorstore from the reviews\n",
        "3. Create a `RetrievalQA` chain \n",
        "\n",
        "## Ship ðŸš¢\n",
        "\n",
        "Create a Hugging Face Space that hosts your application.\n",
        "\n",
        "## Share ðŸš€\n",
        "\n",
        "Make a social media post about your final application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BBraMxjrwOx"
      },
      "source": [
        ">### Why RAQA and not RAG?\n",
        ">If we look at the original [paper](https://arxiv.org/abs/2005.11401), we find that RAG is a fairly specific and well defined term that isn't exactly the same as \"retrieve context, feed context to model in the prompt\".\n",
        ">For that reason, we're making the decision to delineate between \"actual\" RAG, and Retrieval Augmented Question Answering - which is not a well defined phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcL8585DsZML"
      },
      "source": [
        "### Pre-task Work\n",
        "\n",
        "All we really need to do to get started is to get our prerequisites!\n",
        "\n",
        "We'll be leveraging `langchain`, `openai`, and `pinecone` today.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [OpenAI](https://github.com/openai/openai-python)\n",
        "- [Pinecone](https://docs.pinecone.io/docs/overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vQa6rjDLqPCI"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U openai langchain \"pinecone-client[grpc]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wF8_ODX5h-P",
        "outputId": "f3395c72-029b-4e49-f0b9-aba7e3c2195f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Pinecone API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"PINECONE_ENV\"] = getpass.getpass(\"Pinecone Environment:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLrL342RtWxf"
      },
      "source": [
        "### Task 1: Data Preparation\n",
        "\n",
        "In this task we'll be collecting, and then parsing, our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh8QTtMhzY_g"
      },
      "source": [
        "#### Scraping IMDB Reviews of Barbie\n",
        "\n",
        "We'll use some Selenium based trickery to get the reviews we need to make our application.\n",
        "\n",
        "Check out the docs here:\n",
        "- [Selenium](https://www.selenium.dev/documentation/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PsGPV2zHuCj2"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCNCZdzrw81B",
        "outputId": "f74cc223-af93-491a-e92e-5d7ee1355d49"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U scrapy selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will need to install the `chromium-chromedriver` in order to use the method presented. \n",
        "\n",
        "`!apt install chromium-chromedriver` will install the chromedriver. \n",
        "\n",
        "You may have to use your terminal if you receive an error related to `sudo`. In that case, please use (in your terminal) `sudo apt install chromium-chromedriver`.\n",
        "\n",
        "Otherwise, the `.csv` is provided and can be loaded through `pandas` if you're experiencing issues relating to the web-scraping portion of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Niq6DKMOwPIn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scrapy.selector import Selector\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k9AA_f-DxGyv"
      },
      "outputs": [],
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IsjYL7K_y1ip"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.imdb.com/title/tt1517268/reviews/?ref_=tt_ov_rt\"\n",
        "driver.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XPGysdwuy190"
      },
      "outputs": [],
      "source": [
        "sel = Selector(text = driver.page_source)\n",
        "review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
        "more_review_pages = int(int(review_counts)/25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSJ0vuDy4D2",
        "outputId": "5bd75470-a74a-4b2c-ba76-a9025d71c79b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:01<00:00, 45.63it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(more_review_pages)):\n",
        "    try:\n",
        "        css_selector = 'load-more-trigger'\n",
        "        driver.find_element(By.ID, css_selector).click()\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46cAciBxr2C",
        "outputId": "d5a8737f-6162-434c-ef82-81317490960d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/75 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<00:00, 115.15it/s]\n"
          ]
        }
      ],
      "source": [
        "rating_list = []\n",
        "review_date_list = []\n",
        "review_title_list = []\n",
        "author_list = []\n",
        "review_list = []\n",
        "review_url_list = []\n",
        "error_url_list = []\n",
        "error_msg_list = []\n",
        "reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
        "\n",
        "for d in tqdm(reviews):\n",
        "    try:\n",
        "        sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
        "        try:\n",
        "            rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
        "        except:\n",
        "            rating = np.NaN\n",
        "        try:\n",
        "            review = sel2.css('.text.show-more__control::text').extract_first()\n",
        "        except:\n",
        "            review = np.NaN\n",
        "        try:\n",
        "            review_date = sel2.css('.review-date::text').extract_first()\n",
        "        except:\n",
        "            review_date = np.NaN\n",
        "        try:\n",
        "            author = sel2.css('.display-name-link a::text').extract_first()\n",
        "        except:\n",
        "            author = np.NaN\n",
        "        try:\n",
        "            review_title = sel2.css('a.title::text').extract_first()\n",
        "        except:\n",
        "            review_title = np.NaN\n",
        "        try:\n",
        "            review_url = sel2.css('a.title::attr(href)').extract_first()\n",
        "        except:\n",
        "            review_url = np.NaN\n",
        "        rating_list.append(rating)\n",
        "        review_date_list.append(review_date)\n",
        "        review_title_list.append(review_title)\n",
        "        author_list.append(author)\n",
        "        review_list.append(review)\n",
        "        review_url_list.append(review_url)\n",
        "    except Exception as e:\n",
        "        error_url_list.append(url)\n",
        "        error_msg_list.append(e)\n",
        "review_df = pd.DataFrame({\n",
        "    'Review_Date':review_date_list,\n",
        "    'Author':author_list,\n",
        "    'Rating':rating_list,\n",
        "    'Review_Title':review_title_list,\n",
        "    'Review':review_list,\n",
        "    'Review_Url':review_url\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W9A0C1tbyfuh",
        "outputId": "8a333f0d-5af6-42f0-f623-c35dbc3170bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>LoveofLegacy</td>\n",
              "      <td>6</td>\n",
              "      <td>Beautiful film, but so preachy\\n</td>\n",
              "      <td>Margot does the best with what she's given, bu...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26 July 2023</td>\n",
              "      <td>aherdofbeautifulwildponies</td>\n",
              "      <td>6</td>\n",
              "      <td>A Hot Pink Mess\\n</td>\n",
              "      <td>Before making Barbie (2023),</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>imseeg</td>\n",
              "      <td>7</td>\n",
              "      <td>3 reasons FOR seeing it and 1 reason AGAINST.\\n</td>\n",
              "      <td>The first reason to go see it:</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31 July 2023</td>\n",
              "      <td>ramair350</td>\n",
              "      <td>10</td>\n",
              "      <td>As a guy I felt some discomfort, and that's o...</td>\n",
              "      <td>As much as it pains me to give a movie called ...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>Natcat87</td>\n",
              "      <td>6</td>\n",
              "      <td>Too heavy handed\\n</td>\n",
              "      <td>As a woman that grew up with Barbie, I was ver...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>23 July 2023</td>\n",
              "      <td>nethy-nho</td>\n",
              "      <td>10</td>\n",
              "      <td>Barbie is not a simple live action of a timel...</td>\n",
              "      <td>But it is also in its smallest details, from t...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>23 August 2023</td>\n",
              "      <td>the_oak</td>\n",
              "      <td>7</td>\n",
              "      <td>Brilliant first part, second part a bit confu...</td>\n",
              "      <td>I loved the first part of this movie. There is...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1 August 2023</td>\n",
              "      <td>tforbes-2</td>\n",
              "      <td>10</td>\n",
              "      <td>Mind blowing\\n</td>\n",
              "      <td>Barbie is simply a mind-blowing experience, an...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>26 July 2023</td>\n",
              "      <td>JPARM-IMDb</td>\n",
              "      <td>6</td>\n",
              "      <td>Expected more from Greta Gerwig\\n</td>\n",
              "      <td>Even though I'm not the target audience for th...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>22 July 2023</td>\n",
              "      <td>fernandoschiavi</td>\n",
              "      <td>5</td>\n",
              "      <td>\"Barbie\" is fun and visually beautiful, but u...</td>\n",
              "      <td>Despite the strong commercial tone, it is stil...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Review_Date                      Author Rating  \\\n",
              "0     21 July 2023                LoveofLegacy      6   \n",
              "1     26 July 2023  aherdofbeautifulwildponies      6   \n",
              "2     22 July 2023                      imseeg      7   \n",
              "3     31 July 2023                   ramair350     10   \n",
              "4     22 July 2023                    Natcat87      6   \n",
              "..             ...                         ...    ...   \n",
              "70    23 July 2023                   nethy-nho     10   \n",
              "71  23 August 2023                     the_oak      7   \n",
              "72   1 August 2023                   tforbes-2     10   \n",
              "73    26 July 2023                  JPARM-IMDb      6   \n",
              "74    22 July 2023             fernandoschiavi      5   \n",
              "\n",
              "                                         Review_Title  \\\n",
              "0                    Beautiful film, but so preachy\\n   \n",
              "1                                   A Hot Pink Mess\\n   \n",
              "2     3 reasons FOR seeing it and 1 reason AGAINST.\\n   \n",
              "3    As a guy I felt some discomfort, and that's o...   \n",
              "4                                  Too heavy handed\\n   \n",
              "..                                                ...   \n",
              "70   Barbie is not a simple live action of a timel...   \n",
              "71   Brilliant first part, second part a bit confu...   \n",
              "72                                     Mind blowing\\n   \n",
              "73                  Expected more from Greta Gerwig\\n   \n",
              "74   \"Barbie\" is fun and visually beautiful, but u...   \n",
              "\n",
              "                                               Review  \\\n",
              "0   Margot does the best with what she's given, bu...   \n",
              "1                       Before making Barbie (2023),    \n",
              "2                      The first reason to go see it:   \n",
              "3   As much as it pains me to give a movie called ...   \n",
              "4   As a woman that grew up with Barbie, I was ver...   \n",
              "..                                                ...   \n",
              "70  But it is also in its smallest details, from t...   \n",
              "71  I loved the first part of this movie. There is...   \n",
              "72  Barbie is simply a mind-blowing experience, an...   \n",
              "73  Even though I'm not the target audience for th...   \n",
              "74  Despite the strong commercial tone, it is stil...   \n",
              "\n",
              "                        Review_Url  \n",
              "0   /review/rw9207456/?ref_=tt_urv  \n",
              "1   /review/rw9207456/?ref_=tt_urv  \n",
              "2   /review/rw9207456/?ref_=tt_urv  \n",
              "3   /review/rw9207456/?ref_=tt_urv  \n",
              "4   /review/rw9207456/?ref_=tt_urv  \n",
              "..                             ...  \n",
              "70  /review/rw9207456/?ref_=tt_urv  \n",
              "71  /review/rw9207456/?ref_=tt_urv  \n",
              "72  /review/rw9207456/?ref_=tt_urv  \n",
              "73  /review/rw9207456/?ref_=tt_urv  \n",
              "74  /review/rw9207456/?ref_=tt_urv  \n",
              "\n",
              "[75 rows x 6 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gHLLYflzw_f"
      },
      "source": [
        "Let's save this `pd.DataFrame` as a `.csv` to our local session (this will be terminated when you terminate the Colab session) so we can leverage it in LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N9FDhwbNz64p"
      },
      "outputs": [],
      "source": [
        "review_df.to_csv(\"./barbie.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = review_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtBD1H8ezNLO"
      },
      "source": [
        "#### Data Parsing\n",
        "\n",
        "Now that we have our data - let's go ahead and set up some tools to parse it into a more usable format for LangChain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CTameZZ0r76"
      },
      "source": [
        "Our reviews might contain a lot of information, and in order to ensure they don't exceed the context window of our model and to allow us to include a few reviews as context for each query - let's construct a system to \"chunk\" our data into smaller pieces.\n",
        "\n",
        "We'll be leveraging the `RecursiveCharacterTextSplitter` for this task today.\n",
        "\n",
        "While splitting our text seems like a simple enough task - getting this correct/incorrect can have massive downstream impacts on your application's performance.\n",
        "\n",
        "You can read the docs here:\n",
        "- [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter)\n",
        "\n",
        "> ### HINT:\n",
        ">It's always worth it to check out the LangChain source code if you're ever in a bind - for instance, if you want to know how to transform a set of documents, check it out [here](https://github.com/langchain-ai/langchain/blob/5e9687a196410e9f41ebcd11eb3f2ca13925545b/libs/langchain/langchain/text_splitter.py#L268C18-L268C18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uEgcUVtl00Xm"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = ### YOUR CODE HERE, # the character length of the chunk\n",
        "    chunk_overlap = ### YOUR CODE HERE, # the character length of the overlap between chunks\n",
        "    length_function = ### YOUR CODE HERE, # the length function - in this case, character length (aka the python len() fn.)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylT4jwmx3zCb"
      },
      "source": [
        "Now that we have our `RecursiveCharacterTextSplitter` set up - let's look at how it might split our source text. \n",
        "\n",
        "Keep in mind that the source text is split by `[\"\\n\\n\", \"\\n\", \" \", \"\"]` in that order.\n",
        "\n",
        "We know that each of the subheadings in our review `page_content` is separated by a newline character, so it will preferably chunk the review subheadings together. \n",
        "\n",
        "That's great! Let's move on to creating our index!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cB0L_CN38W5"
      },
      "source": [
        "### Task 2: Creating an \"Index\"\n",
        "\n",
        "The term \"index\" is used largely to mean: Structured documents parsed into a useful format for querying, retrieving, and use in the LLM application stack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GycdG53N4f9Z"
      },
      "source": [
        "#### Selecting Our VectorStore\n",
        "\n",
        "There are a number of different VectorStores, and a number of different strengths and weaknesses to each.\n",
        "\n",
        "In this notebook, we will be keeping it very simple by leveraging Pinecone's API Vector Database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5o4vwSn4hfe",
        "outputId": "62bf250d-1c4f-49c3-b154-71e52d530ddf"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set up a Pinecone index using the methods provided in their [documentation](https://docs.pinecone.io/docs/langchain)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "YOUR_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
        "YOUR_ENV = os.environ[\"PINECONE_ENV\"]\n",
        "\n",
        "index_name = 'barbie-review-index'\n",
        "\n",
        "pinecone.init(\n",
        "    api_key= ### YOUR CODE HERE,\n",
        "    environment= ### YOUR CODE HERE\n",
        ")\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    # we create a new index\n",
        "    pinecone.create_index(\n",
        "        name=index_name,\n",
        "        metric='cosine',\n",
        "        dimension= ### YOU CODE HERE - REMEMBER TO USE THE SAME DIMENSION AS THE EMBEDDING MODEL (text-embedding-ada-002)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can connect to our index and view some statistics about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 117}},\n",
              " 'total_vector_count': 117}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = pinecone.GRPCIndex(index_name)\n",
        "\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGU96p5R54Xz"
      },
      "source": [
        "We're going to be setting up our VectorStore with the OpenAI embeddings model. While this embeddings model does not need to be consistent with the LLM selection, it does need to be consistent between embedding our index and embedding our queries over that index.\n",
        "\n",
        "While we don't have to worry too much about that in this example - it's something to keep in mind for more complex applications.\n",
        "\n",
        "We're going to leverage a [`CacheBackedEmbeddings`](https://python.langchain.com/docs/modules/data_connection/caching_embeddings ) flow to prevent us from re-embedding similar queries over and over again.\n",
        "\n",
        "Not only will this save time, it will also save us precious embedding tokens, which will reduce the overall cost for our application.\n",
        "\n",
        ">#### Note:\n",
        ">The overall cost savings needs to be compared against the additional cost of storing the cached embeddings for a true cost/benefit analysis. If your users are submitting the same queries often, though, this pattern can be a massive reduction in cost.\n",
        "\n",
        "Documentation:\n",
        " - [`CacheBackedEmbeddings.from_bytes_store()`](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html#langchain.embeddings.cache.CacheBackedEmbeddings.from_bytes_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AOzZWPU05WLr"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "core_embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    ### YOUR CODE HERE, \n",
        "    ### YOUR CODE HERE, \n",
        "    namespace= ### YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our `CacheBackedEmbeddings` pipeline set-up, let's index our documents into our Pinecone Vector Database. \n",
        "\n",
        "We'll add some useful metadata as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Date</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review_Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Review_Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21 July 2023</td>\n",
              "      <td>LoveofLegacy</td>\n",
              "      <td>6</td>\n",
              "      <td>Beautiful film, but so preachy\\n</td>\n",
              "      <td>Margot does the best with what she's given, bu...</td>\n",
              "      <td>/review/rw9207456/?ref_=tt_urv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Review_Date        Author Rating                       Review_Title  \\\n",
              "0  21 July 2023  LoveofLegacy      6   Beautiful film, but so preachy\\n   \n",
              "\n",
              "                                              Review  \\\n",
              "0  Margot does the best with what she's given, bu...   \n",
              "\n",
              "                       Review_Url  \n",
              "0  /review/rw9207456/?ref_=tt_urv  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:00<00:00, 9635.29it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from uuid import uuid4\n",
        "\n",
        "BATCH_LIMIT = 100\n",
        "\n",
        "texts = []\n",
        "metadatas = []\n",
        "\n",
        "for i in tqdm(range(len(data))):\n",
        "\n",
        "    record = data.iloc[i]\n",
        "\n",
        "    metadata = {\n",
        "        'review-url': str(record[\"Review_Url\"]),\n",
        "        'review-date' : ### YOUR CODE HERE,\n",
        "        'author' : ### YOUR CODE HERE,\n",
        "        'rating' : ### YOUR CODE HERE,\n",
        "        'review-title' : ### YOUR CODE HERE,\n",
        "    }\n",
        "\n",
        "    record_texts = text_splitter.split_text(\n",
        "        ### YOUR CODE HERE\n",
        "        )\n",
        "\n",
        "    record_metadatas = [{\n",
        "        \"chunk\": j, \"text\": text, **metadata\n",
        "    } for j, text in enumerate(record_texts)]\n",
        "    texts.extend(record_texts)\n",
        "    metadatas.extend(record_metadatas)\n",
        "    \n",
        "    if len(texts) >= BATCH_LIMIT:\n",
        "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "        embeds = embedder.embed_documents(texts)\n",
        "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
        "        texts = []\n",
        "        metadatas = []\n",
        "\n",
        "if len(texts) > 0:\n",
        "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "    embeds = embedder.embed_documents(texts)\n",
        "    index.upsert(vectors=zip(ids, embeds, metadatas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 205}},\n",
              " 'total_vector_count': 205}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've created our index, let's convert it to a LangChain `VectorStroe` so we can use it in the rest of the LangChain ecosystem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"text\"\n",
        "\n",
        "index = pinecone.Index(index_name)\n",
        "\n",
        "vectorstore = Pinecone(\n",
        "    ### YOUR CODE HERE, \n",
        "    ### YOUR CODE HERE, \n",
        "    ### YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGHzcE5i6fOR"
      },
      "source": [
        "Now that we've created the VectorStore, we can check that it's working by embedding a query and retrieving passages from our reviews that are close to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"The film's universe and settings are fantastic. The casting is really good too, with Gosling excelling in the role of Ken.\", metadata={'author': 'hamsterination', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 19, 0, 0), 'review-title': ' It could have been so much better...\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'}),\n",
              " Document(page_content=\"The film's universe and settings are fantastic. The casting is really good too, with Gosling excelling in the role of Ken.\", metadata={'author': 'hamsterination', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 19, 0, 0), 'review-title': ' It could have been so much better...\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}),\n",
              " Document(page_content='This movie is so much fun. It starts off really strong although the story does move away from \"Barbieland\" sooner than I would have liked. Nonetheless, it regains its footing with the final act in particular and I could not stop laughing at Ryan Gosling\\'s portrayal of Ken. That song will forever be stuck in my head.', metadata={'author': 'Genti25', 'chunk': 0.0, 'rating': '8', 'review-date': datetime.datetime(2023, 7, 20, 0, 0), 'review-title': ' You are Kenough\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'})]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Who played Ken?\"\n",
        "\n",
        "vectorstore.similarity_search(\n",
        "    query, \n",
        "    k=3  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4fyOUS-fU-"
      },
      "source": [
        "Let's see how much time the `CacheBackedEmbeddings` pattern saves us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCwtsJbc_KPd",
        "outputId": "92acfeb8-26e8-4dd8-d247-29fea2ca5187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "236 ms Â± 34.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "query = \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow.\"\n",
        "vectorstore.similarity_search(\n",
        "    query, \n",
        "    k=3  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4utL1EfARTm"
      },
      "source": [
        "As we can see, even over a significant number of runs - the cached query is significantly faster than the first instance of the query!\n",
        "\n",
        "With that, we're ready to move onto Task 3!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po3kHNHGBp0j"
      },
      "source": [
        "### Task 3: Building a Retrieval Chain\n",
        "\n",
        "In this task, we'll be making a Retrieval Chain which will allow us to ask semantic questions over our data.\n",
        "\n",
        "This part is rather abstracted away from us in LangChain and so it seems very powerful.\n",
        "\n",
        "Be sure to check the documentation, the source code, and other provided resources to build a deeper understanding of what's happening \"under the hood\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Ux9XdzCDi9"
      },
      "source": [
        "#### A Basic RetrievalQA Chain\n",
        "\n",
        "We're going to leverage `return_source_documents=True` to ensure we have proper sources for our reviews - should the end user want to verify the reviews themselves.\n",
        "\n",
        "Hallucinations [are](https://arxiv.org/abs/2202.03629) [a](https://arxiv.org/abs/2305.15852) [massive](https://arxiv.org/abs/2303.16104) [problem](https://arxiv.org/abs/2305.18248) in LLM applications.\n",
        "\n",
        "Though it has been tenuously shown that using Retrieval Augmentation [reduces hallucination in conversations](https://arxiv.org/pdf/2104.07567.pdf), one sure fire way to ensure your model is not hallucinating in a non-transparent way is to provide sources with your responses. This way the end-user can verify the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_waVo3AEk71"
      },
      "source": [
        "#### Our LLM\n",
        "\n",
        "In this notebook, we'll continue to leverage OpenAI's suite of models - this time we'll be using the `gpt-3.5-turbo` model to power our RetrievalQAWithSources chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QfglvbBtExPR"
      },
      "outputs": [],
      "source": [
        "from langchain.llms.openai import OpenAIChat\n",
        "\n",
        "llm = OpenAIChat(\n",
        "    model=### YOUR CODE HERE, \n",
        "    temperature=### YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w35ZkVEoE8II"
      },
      "source": [
        "Now we can set up our chain.\n",
        "\n",
        "First, we need to leverage our `VectorStore` as a retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T8TWJMH8F_w7"
      },
      "outputs": [],
      "source": [
        "retriever = ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QeD8R6huFIf6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPaII9nF72R",
        "outputId": "0b46128f-edbe-4010-afdc-36603f25c4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Will Ferrell ruined every scene he was in.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"How was Will Ferrell in this movie?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ov7N22MxOS",
        "outputId": "aeb6271b-4161-4921-e07c-b5f9041e9c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is not possible to determine whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the available metadata we have, thanks to our index-creation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result = qa_with_sources_chain({\"query\" : \"Was Will Ferrel funny?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Key: query\n",
            "Value: Was Will Ferrel funny?\n",
            "\n",
            "Key: result\n",
            "Value: No, the person states that Will Ferrell ruined every scene he was in.\n",
            "\n",
            "Key: source_documents\n",
            "Value: [Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'}), Document(page_content=\"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\", metadata={'author': 'agjbull', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'}), Document(page_content=\"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\", metadata={'author': 'Revuer223', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'}), Document(page_content=\"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\", metadata={'author': 'Revuer223', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for k, v in result.items():\n",
        "    print(f\"Key: {k}\")\n",
        "    print(f\"Value: {v}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadata: ('metadata', {'author': 'agjbull', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'agjbull', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Just a little empty\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"I really wanted to enjoy this and I know that I am not the target audience but there were massive plot holes and no real flow. The film was very disjointed. Ryan Gosling as good as he is seemed to old to play Ken and Will Ferrell ruined every scene he was in. I just didn't get it, it seemed hollow artificial and hackneyed. A waste of some great talent. It was predictable without being reassuring and trying so hard to be woke in the most superficial way in that but trying to tick so many boxes it actually ticked none. Margo Robbie looks beautiful throughout, the costumes and the sets were amazing but the story was way too weak and didn't make much sense at all.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'Revuer223', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9207456/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\")\n",
            "\n",
            "Metadata: ('metadata', {'author': 'Revuer223', 'chunk': 0.0, 'rating': '6', 'review-date': datetime.datetime(2023, 7, 23, 0, 0), 'review-title': ' Could Have Been Great. 2nd Half Brings It Down.\\n', 'review-url': '/review/rw9221648/?ref_=tt_urv'})\n",
            "Page Content: ('page_content', \"The quality, the humor, and the writing of the movie is fun for a while. It's quirky and it's unique. When they get into the weeds and try to explore deeper themes, the movie is a miss. The middle expositional phase of the movie, I must say, is a bore.\")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for page_content, metadata in result[\"source_documents\"]:\n",
        "    print(f\"Metadata: {metadata}\")\n",
        "    print(f\"Page Content: {page_content}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Prompt Caching and Monitoring\n",
        "\n",
        "Now that we have the basic `RetrievalQAChain` set up and working - let's add a few more tools to help us built a more performant application and add a visibility tool as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visibility Tooling\n",
        "\n",
        "We'll be once again leveraging Weights and Biases as our visibility tool, so let's add that first!\n",
        "\n",
        "You'll want to use the same Weights and Biases account that you set-up last Thursday here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"Weights and Biases API Key:\")\n",
        "os.environ[\"WANDB_PROJECT\"] = \"barbie-retrieval-qa\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to set up WandB, all we have to do is..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q -U wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yes, that's it. \n",
        "\n",
        "Let's use our `RetrievalQA` chain to test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/fourthbrain/barbie-retrieval-qa/runs/q3no0qvl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is not possible to determine whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With those simple lines of code - we've added full visibility to our prompts and responses through Weights and Biases! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prompt Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding A Prompt Cache\n",
        "\n",
        "The basic idea of Prompt Caching is to provide a way to circumvent going to the LLM for prompts we have already seen.\n",
        "\n",
        "Similar to cached embeddings, the idea is simple:\n",
        "\n",
        "- Keep track of all the input/output pairs\n",
        "- If a user query is (in the case of semantic similarity caches) close enough to a previous prompt contained in the cache, return the output associated with that pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing a Prompt Cache\n",
        "\n",
        "There are many different tools you can use to implement a Prompt Cache - from a \"build it yourself\" VectorStore implementation - to Redis - to custom libraries - there are upsides and downsides to each solution. \n",
        "\n",
        "Let's look at the Redis-backed Cache vs. `InMemoryCache` as an example:\n",
        "\n",
        "Redis Cache\n",
        "| Pros  | Cons  |\n",
        "|---|---|\n",
        "| Managed and Robust  | Expensive to Host  |\n",
        "| Integrations on all Major Cloud Platforms  | Non-trivial to Integrate |\n",
        "| Easily Scalable  | Does not have a ChatModel implementation |\n",
        "\n",
        "`InMemoryCache`\n",
        "| Pros  | Cons  |\n",
        "|---|---|\n",
        "| Easily implemented  | Consumes potentially precious memory |\n",
        "| Completely Cloud Agnostic  | Does not offer inter-session caching |\n",
        "\n",
        "For the sake of ease of use - and to allow functionality with our `ChatOpenAI` model - we'll leverage `InMemoryCache`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to set our `langchain.llm_cache` to use the `InMemoryCache`.\n",
        "\n",
        "- [`InMemoryCache`](https://api.python.langchain.com/en/latest/cache/langchain.cache.InMemoryCache.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.cache import InMemoryCache\n",
        "langchain.llm_cache = InMemoryCache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One more important fact about the `InMemoryCache` is that it is what's called an \"exact-match\" cache - meaning it will only trigger when the user query is *exactly* represented in the cache. \n",
        "\n",
        "This is a safer cache, as we can guarentee the user's query exactly matches with previous queries and we don't have to worry about edge-cases where semantic similarity might fail - but it does reduce the potential to hit the cache.\n",
        "\n",
        "We could leverage tools like `GPTCache`, or `RedisCache` (for non-chat model implementations) to get a \"semantic similarity\" cache, if desired!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CPU times: user 109 ms, sys: 781 Âµs, total: 109 ms\n",
            "Wall time: 1.8 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is not possible to determine whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CPU times: user 23 ms, sys: 4 Âµs, total: 23 ms\n",
            "Wall time: 269 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is not possible to determine whether reviewers consider this movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at an example that is extremely close - but is not the exact query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CPU times: user 65.2 ms, sys: 4.1 ms, total: 69.3 ms\n",
            "Wall time: 1.77 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Based on the given context, it is difficult to determine whether reviewers consider the movie \"Kenough\" or not.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "qa_with_sources_chain({\"query\" : \"Do reviewers consider this here movie Kenough?\"})[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, adding an exact-match prompt cache is a very small lift - but it can significantly improve the latency of your end-user application experience!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQVCkoy3H5Rw"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "And with that, we have our Barbie Review RAQA Application built!\n",
        "\n",
        "Let's port it into a Chainlit app and put it up on a Hugging Face Space!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOiWOWtcIc3OpL6fUrMAdOt",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
